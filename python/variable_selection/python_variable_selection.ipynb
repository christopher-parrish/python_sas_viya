{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advisor                            int64\n",
      "advisor_event_indicator            int64\n",
      "sf_face_2_face                     int64\n",
      "sf_call_outbound                   int64\n",
      "sf_call_inbound                    int64\n",
      "sf_email_inbound                   int64\n",
      "channel_bank                       int64\n",
      "channel_wirehouse                  int64\n",
      "channel_ria                        int64\n",
      "primary_prod_sold_fixed            int64\n",
      "primary_prod_sold_va               int64\n",
      "sf_email_campaigns                 int64\n",
      "advisor_hh_children                int64\n",
      "annuity_mkt_opp                  float64\n",
      "advisor_advising_years           float64\n",
      "advisor_aum                      float64\n",
      "advisor_annuity_selling_years    float64\n",
      "advisor_age                      float64\n",
      "advisor_net_worth                float64\n",
      "advisor_credit_hist_mos          float64\n",
      "advisor_firm_changes               int64\n",
      "advisor_credit_score             float64\n",
      "wholesaler                         int64\n",
      "region_ca                          int64\n",
      "region_ny                          int64\n",
      "region_fl                          int64\n",
      "region_tx                          int64\n",
      "region_ne                          int64\n",
      "region_so                          int64\n",
      "region_mw                          int64\n",
      "region_we                          int64\n",
      "sf_email_responses                 int64\n",
      "analytic_partition                 int64\n",
      "dtype: object\n",
      "Dimenstions of Data: (15351, 33)\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "### Create Dataframe ###\n",
    "########################\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "workspace_dir = \"/workspaces/chris_parrish/sas_viya/data/annuity_advisors\"\n",
    "data_table = \"annuity_advisors_prep.csv\"\n",
    "\n",
    "dm_inputdf = pd.read_csv(Path(workspace_dir) / data_table, header=0)\n",
    "print(dm_inputdf.dtypes)\n",
    "print(\"Dimenstions of Data:\", dm_inputdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "### Model Parameters ###\n",
    "########################\n",
    "\n",
    "### import python libraries\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "### model manager information\n",
    "metadata_output_dir = 'outputs'\n",
    "model_name = 'logit_python_annuity_workbench'\n",
    "project_name = 'Annuity Advisors'\n",
    "description = 'Logistic Regression'\n",
    "model_type = 'logistic_regression'\n",
    "model_function = 'Classification'\n",
    "predict_syntax = 'predict_proba'\n",
    "\n",
    "### define macro variables for model\n",
    "dm_dec_target = 'advisor_event_indicator'\n",
    "dm_partitionvar = 'analytic_partition'\n",
    "create_new_partition = 'no' # 'yes', 'no'\n",
    "dm_key = 'advisor' \n",
    "dm_classtarget_level = ['0', '1']\n",
    "dm_partition_validate_val, dm_partition_train_val, dm_partition_test_val = [0, 1, 2]\n",
    "dm_partition_validate_perc, dm_partition_train_perc, dm_partition_test_perc = [0.3, 0.6, 0.1]\n",
    "\n",
    "### create list of regressors\n",
    "keep_predictors = [\n",
    "    ]\n",
    "rejected_predictors = [\n",
    "    'channel_ria',\n",
    "    'region_we',\n",
    "    'primary_prod_sold_fixed'\n",
    "    ] \n",
    "\n",
    "### mlflow\n",
    "use_mlflow = 'no' # 'yes', 'no'\n",
    "mlflow_run_to_use = 0\n",
    "mlflow_class_labels =['TENSOR']\n",
    "mlflow_predict_syntax = 'predict'\n",
    "\n",
    "### var to consider in bias assessment\n",
    "bias_vars = []\n",
    "\n",
    "### var to consider in partial dependency\n",
    "pd_var1 = ''\n",
    "pd_var2 = ''\n",
    "\n",
    "### create partition column, if not already in dataset\n",
    "if create_new_partition == 'yes':\n",
    "    dm_inputdf = shuffle(dm_inputdf)\n",
    "    dm_inputdf.reset_index(inplace=True, drop=True)\n",
    "    validate_rows = round(len(dm_inputdf)*dm_partition_validate_perc)\n",
    "    train_rows = round(len(dm_inputdf)*dm_partition_train_perc) + validate_rows\n",
    "    test_rows = len(dm_inputdf)-train_rows\n",
    "    dm_inputdf.loc[0:validate_rows,dm_partitionvar] = dm_partition_validate_val\n",
    "    dm_inputdf.loc[validate_rows:train_rows,dm_partitionvar] = dm_partition_train_val\n",
    "    dm_inputdf.loc[train_rows:,dm_partitionvar] = dm_partition_test_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sf_face_2_face', 'sf_call_outbound', 'sf_call_inbound', 'sf_email_inbound', 'channel_bank', 'channel_wirehouse', 'primary_prod_sold_va', 'sf_email_campaigns', 'advisor_hh_children', 'annuity_mkt_opp', 'advisor_advising_years', 'advisor_aum', 'advisor_annuity_selling_years', 'advisor_age', 'advisor_net_worth', 'advisor_credit_hist_mos', 'advisor_firm_changes', 'advisor_credit_score', 'wholesaler', 'region_ca', 'region_ny', 'region_fl', 'region_tx', 'region_ne', 'region_so', 'region_mw', 'sf_email_responses']\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "### Final Modeling Columns ###\n",
    "##############################\n",
    "\n",
    "### create list of model variables\n",
    "dm_input = list(dm_inputdf.columns.values)\n",
    "macro_vars = (dm_dec_target + ' ' + dm_partitionvar + ' ' + dm_key).split()\n",
    "#rejected_predictors = [i for i in dm_input if i not in keep_predictors]\n",
    "rejected_vars = rejected_predictors + macro_vars #(include macro_vars if rejected_predictors are explicitly listed - not contra keep_predictors)\n",
    "for i in rejected_vars:\n",
    "    dm_input.remove(i)\n",
    "print(dm_input)\n",
    "\n",
    "### create prediction variables\n",
    "dm_predictionvar = [str('P_') + dm_dec_target + dm_classtarget_level[0], str('P_') + dm_dec_target + dm_classtarget_level[1]]\n",
    "dm_classtarget_intovar = str('I_') + dm_dec_target\n",
    "\n",
    "##################\n",
    "### Data Split ###\n",
    "##################\n",
    "\n",
    "### create train, test, validate datasets using existing partition column\n",
    "dm_traindf = dm_inputdf[dm_inputdf[dm_partitionvar] == dm_partition_train_val]\n",
    "X_train = dm_traindf.loc[:, dm_input]\n",
    "y_train = dm_traindf[dm_dec_target]\n",
    "dm_testdf = dm_inputdf.loc[(dm_inputdf[dm_partitionvar] == dm_partition_test_val)]\n",
    "X_test = dm_testdf.loc[:, dm_input]\n",
    "y_test = dm_testdf[dm_dec_target]\n",
    "dm_validdf = dm_inputdf.loc[(dm_inputdf[dm_partitionvar] == dm_partition_validate_val)]\n",
    "X_valid = dm_validdf.loc[:, dm_input]\n",
    "y_valid = dm_validdf[dm_dec_target]\n",
    "fullX = dm_inputdf.loc[:, dm_input]\n",
    "fully = dm_inputdf[dm_dec_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to complete feature selection with Python: 1334.2509982585907\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### Variable Selection ###\n",
    "##########################\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "### Recursive Feature Elimination (RFE) with Crossvalidation (auto-select number of variables)\n",
    "models_for_rfe = [DecisionTreeRegressor(), GradientBoostingRegressor(), RandomForestRegressor()]\n",
    "start = time()\n",
    "rfe_cols_cv = []\n",
    "for i in models_for_rfe:\n",
    "    rfe_cv = RFECV(estimator=i, step=1, cv=10, min_features_to_select=1)\n",
    "    rfe_cv.fit(fullX,fully)\n",
    "    rfe_cols_cv.append(list(rfe_cv.get_feature_names_out()))\n",
    "\n",
    "finish = time()\n",
    "\n",
    "time_to_complete = finish-start\n",
    "print(\"Time to complete feature selection with Python:\", time_to_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected variables using Scikit-Learn Decision Tree: ['sf_call_inbound', 'sf_email_campaigns', 'advisor_hh_children', 'annuity_mkt_opp', 'advisor_advising_years', 'advisor_aum', 'advisor_age', 'advisor_net_worth', 'advisor_credit_hist_mos', 'advisor_credit_score']\n",
      "Selected variables using Scikit-Learn Gradient Boosting: ['sf_face_2_face', 'sf_call_inbound', 'sf_email_campaigns', 'advisor_hh_children', 'annuity_mkt_opp', 'advisor_advising_years', 'advisor_aum', 'advisor_age', 'advisor_net_worth', 'advisor_credit_hist_mos', 'advisor_firm_changes', 'advisor_credit_score', 'sf_email_responses']\n",
      "Selected variables using Scikit-Learn Random Forest: ['sf_face_2_face', 'sf_call_outbound', 'sf_call_inbound', 'sf_email_inbound', 'channel_wirehouse', 'primary_prod_sold_va', 'sf_email_campaigns', 'advisor_hh_children', 'annuity_mkt_opp', 'advisor_advising_years', 'advisor_aum', 'advisor_annuity_selling_years', 'advisor_age', 'advisor_net_worth', 'advisor_credit_hist_mos', 'advisor_firm_changes', 'advisor_credit_score', 'wholesaler', 'region_ca', 'region_ny', 'sf_email_responses']\n"
     ]
    }
   ],
   "source": [
    "print (\"Selected variables using Scikit-Learn Decision Tree:\", rfe_cols_cv[0])\n",
    "print (\"Selected variables using Scikit-Learn Gradient Boosting:\", rfe_cols_cv[1])\n",
    "print (\"Selected variables using Scikit-Learn Random Forest:\", rfe_cols_cv[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LogisticRegression()_varlist0'] 0.9544\n",
      "['LogisticRegression()_varlist1'] 0.9609\n",
      "['LogisticRegression()_varlist2'] 0.9609\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "### Training Code ###\n",
    "#####################\n",
    "\n",
    "from sasviya.ml.linear_model import LogisticRegression\n",
    "\n",
    "models_for_training_list = [LogisticRegression()]\n",
    "model_results_list = []\n",
    "model_list = []\n",
    "\n",
    "for i in models_for_training_list:\n",
    "    for j in range(0, len(rfe_cols_cv)):\n",
    "        X_train = dm_traindf.loc[:, rfe_cols_cv[j]]\n",
    "        X_test = dm_testdf.loc[:, rfe_cols_cv[j]]\n",
    "        X_valid = dm_validdf.loc[:, rfe_cols_cv[j]]\n",
    "        dm_model = i\n",
    "        dm_model.fit(X_train, y_train)\n",
    "        #cross_val_score(dm_model, X_train, y_train, cv=10, n_jobs=1)\n",
    "        score = dm_model.score(X_valid, y_valid)\n",
    "        model_results_list.append(score)\n",
    "        name = [str(i)[0:20]+str('_varlist')+str(j)]\n",
    "        model_list.append(name)\n",
    "        print('%s %.4f' % (name, score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Workbench Python",
   "language": "python",
   "name": "workbench_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
